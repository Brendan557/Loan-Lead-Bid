{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor # import the random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the data and then fill in NaN BidPrices with 0 to prevent errors when creating and training a model. \n",
    "Note I created a column named 'Bid identifier' which is (ExpectedRevenue)*(ExpectedConversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "BidPrice              0\n",
       "AcceptedBid           0\n",
       "ExpectedRevenue       0\n",
       "ExpectedConversion    0\n",
       "Bid identifier        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leadData = pd.read_csv(\"Lead_Bid_Data.csv\")\n",
    "\n",
    "leadData.isnull().sum()\n",
    "leadData['BidPrice'].fillna(0, inplace=True)\n",
    "leadData.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a SelectedFeatures variables with the column names for the independent variables or the X variables. Y is the dependent variable or the variable I want to predict. I want to see if I can train a model to assign the 'BidPrices' for each 'id'. Later I will create 'rules' to assign the 'BidPrice' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedFeatures = ['ExpectedRevenue', 'ExpectedConversion', 'Bid identifier']\n",
    "X = leadData[SelectedFeatures]\n",
    "y = leadData['BidPrice'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a training and testing set. The test set is 20% of the 'leadData' data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a Decision Tree - will use both the Regressor and Classifier methods to predict the 'BidPrice'\n",
    "I am using the Regressor method for fun as this is more of a Classification type problem and the regressor method will not be limited to the \\\\$3, \\\\$35, \\\\$50, \\\\$75 values for the Bid Price.\n",
    "\n",
    "The Regressor method does not use whole numbers to assign BidPrices, to make the BidPrices viable, i.e. \\\\$3, \\\\$35, \\\\$50, \\\\$75 I created a set of rules to take the values predicted by the model and convert them into viable bids. Using a regressor method and changing the boundaries of the rules converting predicted values to viable values can provide a bit more freedom in which customers are assigned which bid values than a classifier method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTModel = DecisionTreeRegressor()\n",
    "DTModel.fit(X = X_train, y = y_train)\n",
    "y_pred = DTModel.predict(X = X_test)\n",
    "i=0\n",
    "while i < len(y_pred):\n",
    "    if y_pred[i] <= 14.99 and y_pred[i] > 1:\n",
    "        y_pred[i] = 3\n",
    "        i+=1\n",
    "    elif y_pred[i] <=1:\n",
    "        y_pred[i] = 0\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 15 and y_pred[i] <= 39.99:\n",
    "        y_pred[i] = 35\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 40 and y_pred[i] <= 59.99:\n",
    "        y_pred[i] = 50\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 60 and y_pred[i] <= 80:\n",
    "        y_pred[i] = 75\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389249304911955"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 83.9% - this is a little low, I am looking for something in the 90% range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try the DecisionTreeClassifier method. As this method will predict values based on the training set, rules do not need to be created to make sure all predicted bids are viable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCModel = DecisionTreeClassifier()\n",
    "DTCModel.fit(X = X_train, y = y_train)\n",
    "y_pred = DTCModel.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83790546802595"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 83.8%. This is very close to the Regressor methods accuracy but still low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to try and improve accuracy of the prediction I am going to try a Random Forest algorithm instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use both the RandomForestRegressor anbd the RandomForestClassifier. The RandomForestRegressor like the DecisionTreeRegressor method with provide a wide range of predictions so. I am using the same rules/logic to convert the predicted values to viable bids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestRegressor = RandomForestRegressor()\n",
    "forestRegressor.fit(X = X_train, y = y_train)\n",
    "y_pred = forestRegressor.predict(X = X_test)\n",
    "\n",
    "i=0\n",
    "while i < len(y_pred):\n",
    "    if y_pred[i] <= 14.99 and y_pred[i] > 1:\n",
    "        y_pred[i] = 3\n",
    "        i+=1\n",
    "    elif y_pred[i] <=1:\n",
    "        y_pred[i] = 0\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 15 and y_pred[i] <= 39.99:\n",
    "        y_pred[i] = 35\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 40 and y_pred[i] <= 59.99:\n",
    "        y_pred[i] = 50\n",
    "        i+=1\n",
    "    elif y_pred[i] >= 60 and y_pred[i] <= 80:\n",
    "        y_pred[i] = 75\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521779425393883"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 85%, this is still a bit low, but it is better than the Decision Tree Regressor Method. Note that if predicted BidPrices were not converted to the viable bid values, the accuracy_score method above and the confusion_matrix and classification_report methods below would not work and return an error. These methods only work for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5688,  415,  298,    0,    0],\n",
       "       [ 139,  330,  201,    0,    0],\n",
       "       [  14,  225, 2047,   59,   67],\n",
       "       [   0,    0,   18,  116,   50],\n",
       "       [   0,    0,    7,  102, 1014]], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows the number of True and False Positives and Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.89      0.93      6401\n",
      "         3.0       0.34      0.49      0.40       670\n",
      "        35.0       0.80      0.85      0.82      2412\n",
      "        50.0       0.42      0.63      0.50       184\n",
      "        75.0       0.90      0.90      0.90      1123\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10790\n",
      "   macro avg       0.69      0.75      0.71     10790\n",
      "weighted avg       0.88      0.85      0.86     10790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report above shows the precision of the model in predicting each of the values. NOTE, this is after I applied the rules to convert the predicted values to viable values. We can see that \\\\$0, \\\\$35, and \\\\$75 Bid values are pretty precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier - to compare against the Regressor. Uses same training and testing data as the Regressor model.  Here the model predicts \\\\$0, \\\\$3, \\\\$35, \\\\$50, \\\\$75 directly, so no logic is needed to convert the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClassifier = RandomForestClassifier()\n",
    "forestClassifier.fit(X=X_train, y=y_train)\n",
    "y_pred_test = forestClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611677479147358"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 86.1%, slightly better than the Regressor method for predicting BidPrices but still not what I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5955,  179,  267,    0,    0],\n",
       "       [ 287,  197,  186,    0,    0],\n",
       "       [ 174,  124, 2012,   30,   72],\n",
       "       [   1,    1,   41,   95,   46],\n",
       "       [   0,    0,   54,   36, 1033]], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows the number of True and False Positives and Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93      6401\n",
      "         3.0       0.39      0.29      0.34       670\n",
      "        35.0       0.79      0.83      0.81      2412\n",
      "        50.0       0.59      0.52      0.55       184\n",
      "        75.0       0.90      0.92      0.91      1123\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10790\n",
      "   macro avg       0.72      0.70      0.71     10790\n",
      "weighted avg       0.85      0.86      0.86     10790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report above shows the precision of the model in predicting each of the values. We can see that \\\\$0, \\\\$35, and \\\\$75 Bid values are pretty precise. Compared to the Classification report from the regressor method the precision of \\\\$3, and \\\\$50 bids are higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict AcceptedBid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to predict if the bid will be accepted (AcceptedBid =1). This assumes the Bid is already assigned, either through a model or some other method.  For this I will be using the 'BidPrice' given in the \"Soaren_Management_Lead_Bid_Test_Data.csv\" or leadData. The Testing set is 20% of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedFeatures2 = ['BidPrice', 'ExpectedRevenue', 'ExpectedConversion', 'Bid identifier']\n",
    "X2 = leadData[SelectedFeatures2]\n",
    "y2 = leadData['AcceptedBid'].values\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above I am using 4 features. I will again use both the RandomForestClassifier and RandomForestRegressor Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestClassifier2 = RandomForestClassifier()\n",
    "forestClassifier2.fit(X=X_train2, y=y_train2)\n",
    "y_pred_test2 = forestClassifier2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8949953660797034"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2, y_pred_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 89.5% - very close to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7005,  601],\n",
       "       [ 532, 2652]], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_pred_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows the number of True and False Positives and Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      7606\n",
      "           1       0.82      0.83      0.82      3184\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10790\n",
      "   macro avg       0.87      0.88      0.87     10790\n",
      "weighted avg       0.90      0.89      0.90     10790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_pred_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to try the Regressor method. There is logic to convert 'BidAccpeted' to a 0 or 1 as the Regressor method will provide a range of Doubles as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestRegressor2 = RandomForestRegressor()\n",
    "forestRegressor2.fit(X = X_train2, y = y_train2)\n",
    "y_pred2 = forestRegressor2.predict(X = X_test2)\n",
    "\n",
    "i=0\n",
    "while i < len(y_pred2):\n",
    "    if y_pred2[i] >=.5:\n",
    "        y_pred2[i] = 1\n",
    "        i+=1\n",
    "    else:\n",
    "        y_pred2[i] = 0\n",
    "        i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9012048192771084"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 90%, this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6911,  695],\n",
       "       [ 371, 2813]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows the number of True and False Positives and Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      7606\n",
      "           1       0.80      0.88      0.84      3184\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10790\n",
      "   macro avg       0.88      0.90      0.88     10790\n",
      "weighted avg       0.91      0.90      0.90     10790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to compare the Random Forest algorithm to a Logistic Regression model. The model will use the same training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "LogisticRegression accuracy is 0.918\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train2, y_train2)\n",
    "y_log_pred = logreg.predict(X_test2)\n",
    "\n",
    "print('Train/Test split results:')\n",
    "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test2, y_log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the Logistic Regression model is a bit better than the Random Forest models. This is the model I would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      7606\n",
      "           1       0.81      0.94      0.87      3184\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10790\n",
      "   macro avg       0.89      0.92      0.91     10790\n",
      "weighted avg       0.93      0.92      0.92     10790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to try the Random Forest Classifier Method here to see how dropping 'ExpectedRevenue' as a feature will affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8945319740500464"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelectedFeatures3 = ['BidPrice', 'ExpectedConversion', 'Bid identifier']\n",
    "X3 = leadData[SelectedFeatures3]\n",
    "y3 = leadData['AcceptedBid'].values\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "forestClassifier3 = RandomForestClassifier()\n",
    "forestClassifier3.fit(X=X_train3, y=y_train3)\n",
    "y_pred_test3 = forestClassifier3.predict(X_test3)\n",
    "\n",
    "accuracy_score(y_test3, y_pred_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has about the same accuracy as the model with 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "LogisticRegression accuracy is 0.918\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(X_train3, y_train3)\n",
    "y_log_pred2 = logreg2.predict(X_test3)\n",
    "\n",
    "print('Train/Test split results:')\n",
    "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test3, y_log_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears to be just as good as the model with 4 features, so I will use the model with 4 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to create rules for assigning BidPrices instead of using a model.\n",
    "I will compare the predicted net revenue of bids that went through against the net revenue of bid that went through for the file. The net revenue of the file is $1,207,654.\n",
    "I have 8 Test cases, each case changes how the 'BidPrice' is assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 140]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData50 = leadData2.loc[(leadData2['Bid identifier'] >= 100) & (leadData2['Bid identifier'] <140)]\n",
    "leadData50['BidPrice'] = 50\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 65) & (leadData2['Bid identifier'] < 100)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 65)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increases number of \\\\$50 bids and decreases number of \\\\$75 bids compared to previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData50 = leadData2.loc[(leadData2['Bid identifier'] >= 100) & (leadData2['Bid identifier'] < 150)]\n",
    "leadData50['BidPrice'] = 50\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 65) & (leadData2['Bid identifier'] < 100)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 65)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreases number of \\\\$50 bids increases number of \\\\$35 bids compared to previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData50 = leadData2.loc[(leadData2['Bid identifier'] >= 110) & (leadData2['Bid identifier'] <150)]\n",
    "leadData50['BidPrice'] = 50\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 65) & (leadData2['Bid identifier'] < 110)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 65)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increases number of \\\\$35 bids decreases number of \\\\$3 bids compared to previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData50 = leadData2.loc[(leadData2['Bid identifier'] >= 110) & (leadData2['Bid identifier'] <150)]\n",
    "leadData50['BidPrice'] = 50\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 60) & (leadData2['Bid identifier'] < 110)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 60)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreases number of \\\\$35 bids increases number of \\\\$3 bids compared to previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData50 = leadData2.loc[(leadData2['Bid identifier'] >= 110) & (leadData2['Bid identifier'] <150)]\n",
    "leadData50['BidPrice'] = 50\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 67) & (leadData2['Bid identifier'] < 110)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 67)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes \\\\$50 bids, increase number of \\\\$35 bids compared to previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData35 = leadData2.loc[(leadData2['Bid identifier'] >= 67) & (leadData2['Bid identifier'] < 150)]\n",
    "leadData35['BidPrice'] = 35\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 67)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes \\\\$35 bid and increases number of \\\\$3 bid compared to previous case. This case does not provide enough (AcceptedBid = 1) so it is not viable as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 150]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 150)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increases the number of \\\\$75 bids and decreases the number of \\\\$3 bids compared to previous case. This case does not provide enough (AcceptedBid = 1) so it is not viable as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData2 = leadData.copy()\n",
    "leadData2['BidPrice']=0\n",
    "\n",
    "leadData75 = leadData2.loc[leadData2['Bid identifier'] >= 100]\n",
    "leadData75['BidPrice'] = 75\n",
    "\n",
    "leadData3 = leadData2.loc[(leadData2['Bid identifier'] >= 20) & (leadData2['Bid identifier'] < 100)]\n",
    "leadData3['BidPrice'] = 3\n",
    "\n",
    "leadDataOther = leadData2.loc[leadData2['Bid identifier'] < 20]\n",
    "leadDataOther['BidPrice'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following used for Test Cases 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadDataNew = leadData75.append(leadData50.append(leadData35.append(leadData3.append(leadDataOther))))\n",
    "leadDataNew = leadDataNew.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following used for Test Case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadDataNew = leadData75.append(leadData35.append(leadData3.append(leadDataOther)))\n",
    "leadDataNew = leadDataNew.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following for Test Case 7-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadDataNew = leadData75.append(leadData3.append(leadDataOther))\n",
    "leadDataNew = leadDataNew.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For all Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using the above rules to assign the BidPrices. I am comparing the prediction (AcceptedBid = 1) of the Random Forest Classifier and Logistic Regression with 4 Features ['BidPrice', 'ExpectedRevenue', 'ExpectedConversion', 'Bid identifier'], and the Random Forest Classifier with 3 Features ['BidPrice', 'ExpectedConversion', 'Bid identifier'].\n",
    "To make sure the number of leads purchased (AcceptedBid = 1) is within 5% of the actual leads purchased (15224-16827), I am checking the sum of (AcceptedBid =1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadData1 = leadDataNew[SelectedFeatures2]\n",
    "final_pred = forestClassifier2.predict(leadData1)\n",
    "leadData2 = leadDataNew[SelectedFeatures3]\n",
    "final_pred2 = forestClassifier3.predict(leadData2)\n",
    "leadData3 = leadDataNew[SelectedFeatures2]\n",
    "final_log_pred = logreg.predict(leadData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadDataNew['BidAcceptedForest2'] = final_pred\n",
    "leadDataNew['BidAcceptedForest3'] = final_pred2\n",
    "leadDataNew['BidAcceptedLogReg'] = final_log_pred\n",
    "leadDataNew['OriginalBidPrice'] = leadData['BidPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying AccepteBid is within (15224-16827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026\n",
      "15432\n",
      "14975\n",
      "15309\n"
     ]
    }
   ],
   "source": [
    "print(leadDataNew['AcceptedBid'].sum())\n",
    "print(leadDataNew['BidAcceptedForest2'].sum())\n",
    "print(leadDataNew['BidAcceptedForest3'].sum())\n",
    "print(leadDataNew['BidAcceptedLogReg'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reordering the columns in the dataframe and writing to wrting results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadDataNew = leadDataNew[['id','OriginalBidPrice','BidPrice','AcceptedBid','BidAcceptedForest2','BidAcceptedForest3', 'BidAcceptedLogReg','ExpectedRevenue','ExpectedConversion','Bid identifier']]\n",
    "leadDataNew.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following uses a Random Forest Classfier model to assign Bid Prices and then predicts if the bids will be accepted using the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = leadData.copy()\n",
    "dataX = data[SelectedFeatures]\n",
    "data_pred = forestClassifier.predict(dataX)\n",
    "data['BidPrice']=data_pred\n",
    "dataBid = data[SelectedFeatures2]\n",
    "data_final_pred = logreg.predict(dataBid)\n",
    "data['AcceptedBid'] = data_final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18881"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['OriginalBidPrice']=leadData['BidPrice']\n",
    "data['OriginalAcceptedBid']=leadData['AcceptedBid']\n",
    "data = data[['id','OriginalBidPrice','OriginalAcceptedBid','BidPrice','AcceptedBid','ExpectedRevenue','ExpectedConversion','Bid identifier']]\n",
    "data['AcceptedBid'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this way produces to many leads the number of leads purchased (AcceptedBid = 1) needs to be within 5% of the actual leads purchased (15224-16827). 18881 is not between 15224 and 16827."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"result1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
